{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nExample of autoencoder model on MNIST dataset using 2dim latent<br>\n", "The autoencoder forces the encoder to discover 2-dim latent vector<br>\n", "that the decoder can recover the original input. The 2-dim latent<br>\n", "vector is projected on 2D space to analyze the distribution of code<br>\n", "in the latent space. The latent space can be navigated by varying the<br>\n", "values of latent vector to produce new MNIST digits.<br>\n", "This autoencoder has modular design. The encoder, decoder and autoencoder<br>\n", "are 3 models that share weights. For example, after training the<br>\n", "autoencoder, the encoder can be used to  generate latent vectors<br>\n", "of input data for low-dim visualization like PCA or TSNE.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import absolute_import\n", "from __future__ import division\n", "from __future__ import print_function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.layers import Dense, Input\n", "from keras.layers import Conv2D, Flatten\n", "from keras.layers import Reshape, Conv2DTranspose\n", "from keras.models import Model\n", "from keras.datasets import mnist\n", "from keras.utils import plot_model\n", "from keras import backend as K"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_results(models,\n", "                 data,\n", "                 batch_size=32,\n", "                 model_name=\"autoencoder_2dim\"):\n", "    \"\"\"Plots 2-dim latent values as scatter plot of digits\n", "        then, plot MNIST digits as function of 2-dim latent vector\n", "    Arguments:\n", "        models (list): encoder and decoder models\n", "        data (list): test data and label\n", "        batch_size (int): prediction batch size\n", "        model_name (string): which model is using this function\n", "    \"\"\"\n", "    encoder, decoder = models\n", "    x_test, y_test = data\n", "    xmin = ymin = -4\n", "    xmax = ymax = +4\n", "    os.makedirs(model_name, exist_ok=True)\n", "    filename = os.path.join(model_name, \"latent_2dim.png\")\n", "    # display a 2D plot of the digit classes in the latent space\n", "    z = encoder.predict(x_test,\n", "                        batch_size=batch_size)\n", "    plt.figure(figsize=(12, 10))\n\n", "    # axes x and y ranges\n", "    axes = plt.gca()\n", "    axes.set_xlim([xmin,xmax])\n", "    axes.set_ylim([ymin,ymax])\n\n", "    # subsample to reduce density of points on the plot\n", "    z = z[0::2]\n", "    y_test = y_test[0::2]\n", "    plt.scatter(z[:, 0], z[:, 1], marker=\"\")\n", "    for i, digit in enumerate(y_test):\n", "        axes.annotate(digit, (z[i, 0], z[i, 1]))\n", "    plt.xlabel(\"z[0]\")\n", "    plt.ylabel(\"z[1]\")\n", "    plt.savefig(filename)\n", "    plt.show()\n", "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n", "    # display a 30x30 2D manifold of the digits\n", "    n = 30\n", "    digit_size = 28\n", "    figure = np.zeros((digit_size * n, digit_size * n))\n", "    # linearly spaced coordinates corresponding to the 2D plot\n", "    # of digit classes in the latent space\n", "    grid_x = np.linspace(xmin, xmax, n)\n", "    grid_y = np.linspace(ymin, ymax, n)[::-1]\n", "    for i, yi in enumerate(grid_y):\n", "        for j, xi in enumerate(grid_x):\n", "            z = np.array([[xi, yi]])\n", "            x_decoded = decoder.predict(z)\n", "            digit = x_decoded[0].reshape(digit_size, digit_size)\n", "            figure[i * digit_size: (i + 1) * digit_size,\n", "                   j * digit_size: (j + 1) * digit_size] = digit\n", "    plt.figure(figsize=(10, 10))\n", "    start_range = digit_size // 2\n", "    end_range = n * digit_size + start_range\n", "    pixel_range = np.arange(start_range, end_range, digit_size)\n", "    sample_range_x = np.round(grid_x, 1)\n", "    sample_range_y = np.round(grid_y, 1)\n", "    plt.xticks(pixel_range, sample_range_x)\n", "    plt.yticks(pixel_range, sample_range_y)\n", "    plt.xlabel(\"z[0]\")\n", "    plt.ylabel(\"z[1]\")\n", "    plt.imshow(figure, cmap='Greys_r')\n", "    plt.savefig(filename)\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load MNIST dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(x_train, y_train), (x_test, y_test) = mnist.load_data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reshape to (28, 28, 1) and normalize input images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_size = x_train.shape[1]\n", "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n", "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n", "x_train = x_train.astype('float32') / 255\n", "x_test = x_test.astype('float32') / 255"]}, {"cell_type": "markdown", "metadata": {}, "source": ["network parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_shape = (image_size, image_size, 1)\n", "batch_size = 32\n", "kernel_size = 3\n", "latent_dim = 2\n", "# encoder/decoder number of CNN layers and filters per layer\n", "layer_filters = [32, 64]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["build the autoencoder model<br>\n", "first build the encoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["inputs = Input(shape=input_shape, name='encoder_input')\n", "x = inputs\n", "# stack of Conv2D(32)-Conv2D(64)\n", "for filters in layer_filters:\n", "    x = Conv2D(filters=filters,\n", "               kernel_size=kernel_size,\n", "               activation='relu',\n", "               strides=2,\n", "               padding='same')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["shape info needed to build decoder model so we don't do hand computation<br>\n", "the input to the decoder's first Conv2DTranspose will have this shape<br>\n", "shape is (7, 7, 64) which is processed by the decoder back to (28, 28, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shape = K.int_shape(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["generate latent vector"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = Flatten()(x)\n", "latent = Dense(latent_dim, name='latent_vector')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["instantiate encoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encoder = Model(inputs, latent, name='encoder')\n", "encoder.summary()\n", "plot_model(encoder, to_file='encoder.png', show_shapes=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["build the decoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n", "# use the shape (7, 7, 64) that was earlier saved\n", "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n", "# from vector to suitable shape for transposed conv\n", "x = Reshape((shape[1], shape[2], shape[3]))(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stack of Conv2DTranspose(64)-Conv2DTranspose(32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filters in layer_filters[::-1]:\n", "    x = Conv2DTranspose(filters=filters,\n", "                        kernel_size=kernel_size,\n", "                        activation='relu',\n", "                        strides=2,\n", "                        padding='same')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reconstruct the input"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outputs = Conv2DTranspose(filters=1,\n", "                          kernel_size=kernel_size,\n", "                          activation='sigmoid',\n", "                          padding='same',\n", "                          name='decoder_output')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["instantiate decoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["decoder = Model(latent_inputs, outputs, name='decoder')\n", "decoder.summary()\n", "plot_model(decoder, to_file='decoder.png', show_shapes=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["autoencoder = encoder + decoder<br>\n", "instantiate autoencoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n", "autoencoder.summary()\n", "plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Mean Square Error (MSE) loss function, Adam optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.compile(loss='mse', optimizer='adam')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["train the autoencoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.fit(x_train,\n", "                x_train,\n", "                validation_data=(x_test, x_test),\n", "                epochs=20,\n", "                batch_size=batch_size)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["predict the autoencoder output from test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_decoded = autoencoder.predict(x_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["display the 1st 8 test input and decoded images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n", "imgs = imgs.reshape((4, 4, image_size, image_size))\n", "imgs = np.vstack([np.hstack(i) for i in imgs])\n", "plt.figure()\n", "plt.axis('off')\n", "plt.title('Input: 1st 2 rows, Decoded: last 2 rows')\n", "plt.imshow(imgs, interpolation='none', cmap='gray')\n", "plt.savefig('input_and_decoded.png')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["project the 2-dim latent on 2D space"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = (encoder, decoder)\n", "data = (x_test, y_test)\n", "plot_results(models, data,\n", "             batch_size=batch_size,\n", "             model_name=\"autoencoder-2dim\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}