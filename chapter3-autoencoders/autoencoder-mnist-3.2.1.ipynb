{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nExample of autoencoder model on MNIST dataset<br>\n", "This autoencoder has modular design. The encoder, decoder and autoencoder<br>\n", "are 3 models that share weights. For example, after training the<br>\n", "autoencoder, the encoder can be used to  generate latent vectors<br>\n", "of input data for low-dim visualization like PCA or TSNE.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import absolute_import\n", "from __future__ import division\n", "from __future__ import print_function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.layers import Dense, Input\n", "from keras.layers import Conv2D, Flatten\n", "from keras.layers import Reshape, Conv2DTranspose\n", "from keras.models import Model\n", "from keras.datasets import mnist\n", "from keras.utils import plot_model\n", "from keras import backend as K"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load MNIST dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(x_train, _), (x_test, _) = mnist.load_data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reshape to (28, 28, 1) and normalize input images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_size = x_train.shape[1]\n", "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n", "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n", "x_train = x_train.astype('float32') / 255\n", "x_test = x_test.astype('float32') / 255"]}, {"cell_type": "markdown", "metadata": {}, "source": ["network parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_shape = (image_size, image_size, 1)\n", "batch_size = 32\n", "kernel_size = 3\n", "latent_dim = 16\n", "# encoder/decoder number of CNN layers and filters per layer\n", "layer_filters = [32, 64]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["build the autoencoder model<br>\n", "first build the encoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["inputs = Input(shape=input_shape, name='encoder_input')\n", "x = inputs\n", "# stack of Conv2D(32)-Conv2D(64)\n", "for filters in layer_filters:\n", "    x = Conv2D(filters=filters,\n", "               kernel_size=kernel_size,\n", "               activation='relu',\n", "               strides=2,\n", "               padding='same')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["shape info needed to build decoder model<br>\n", "so we don't do hand computation<br>\n", "the input to the decoder's first<br>\n", "Conv2DTranspose will have this shape<br>\n", "shape is (7, 7, 64) which is processed by<br>\n", "the decoder back to (28, 28, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shape = K.int_shape(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["generate latent vector"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = Flatten()(x)\n", "latent = Dense(latent_dim, name='latent_vector')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["instantiate encoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encoder = Model(inputs,\n", "                latent,\n", "                name='encoder')\n", "encoder.summary()\n", "plot_model(encoder,\n", "           to_file='encoder.png',\n", "           show_shapes=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["build the decoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n", "# use the shape (7, 7, 64) that was earlier saved\n", "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n", "# from vector to suitable shape for transposed conv\n", "x = Reshape((shape[1], shape[2], shape[3]))(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stack of Conv2DTranspose(64)-Conv2DTranspose(32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filters in layer_filters[::-1]:\n", "    x = Conv2DTranspose(filters=filters,\n", "                        kernel_size=kernel_size,\n", "                        activation='relu',\n", "                        strides=2,\n", "                        padding='same')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reconstruct the input"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outputs = Conv2DTranspose(filters=1,\n", "                          kernel_size=kernel_size,\n", "                          activation='sigmoid',\n", "                          padding='same',\n", "                          name='decoder_output')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["instantiate decoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["decoder = Model(latent_inputs, outputs, name='decoder')\n", "decoder.summary()\n", "plot_model(decoder, to_file='decoder.png', show_shapes=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["autoencoder = encoder + decoder<br>\n", "instantiate autoencoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder = Model(inputs,\n", "                    decoder(encoder(inputs)),\n", "                    name='autoencoder')\n", "autoencoder.summary()\n", "plot_model(autoencoder,\n", "           to_file='autoencoder.png',\n", "           show_shapes=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Mean Square Error (MSE) loss function, Adam optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.compile(loss='mse', optimizer='adam')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["train the autoencoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.fit(x_train,\n", "                x_train,\n", "                validation_data=(x_test, x_test),\n", "                epochs=1,\n", "                batch_size=batch_size)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["predict the autoencoder output from test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_decoded = autoencoder.predict(x_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["display the 1st 8 test input and decoded images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n", "imgs = imgs.reshape((4, 4, image_size, image_size))\n", "imgs = np.vstack([np.hstack(i) for i in imgs])\n", "plt.figure()\n", "plt.axis('off')\n", "plt.title('Input: 1st 2 rows, Decoded: last 2 rows')\n", "plt.imshow(imgs, interpolation='none', cmap='gray')\n", "plt.savefig('input_and_decoded.png')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}