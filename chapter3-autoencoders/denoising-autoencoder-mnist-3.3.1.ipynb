{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nTrains a denoising autoencoder on MNIST dataset.<br>\n", "Denoising is one of the classic applications of autoencoders.<br>\n", "The denoising process removes unwanted noise that corrupted the<br>\n", "true data.<br>\n", "Noise + Data ---> Denoising Autoencoder ---> Data<br>\n", "Given a training dataset of corrupted data as input and<br>\n", "true data as output, a denoising autoencoder can recover the<br>\n", "hidden structure to generate clean data.<br>\n", "This example has modular design. The encoder, decoder and autoencoder<br>\n", "are 3 models that share weights. For example, after training the<br>\n", "autoencoder, the encoder can be used to  generate latent vectors<br>\n", "of input data for low-dim visualization like PCA or TSNE.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import absolute_import\n", "from __future__ import division\n", "from __future__ import print_function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.layers import Dense, Input\n", "from keras.layers import Conv2D, Flatten\n", "from keras.layers import Reshape, Conv2DTranspose\n", "from keras.models import Model\n", "from keras import backend as K\n", "from keras.datasets import mnist\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from PIL import Image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(1337)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load MNIST dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(x_train, _), (x_test, _) = mnist.load_data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reshape to (28, 28, 1) and normalize input images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_size = x_train.shape[1]\n", "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n", "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n", "x_train = x_train.astype('float32') / 255\n", "x_test = x_test.astype('float32') / 255"]}, {"cell_type": "markdown", "metadata": {}, "source": ["generate corrupted MNIST images by adding noise with normal dist<br>\n", "centered at 0.5 and std=0.5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n", "x_train_noisy = x_train + noise\n", "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n", "x_test_noisy = x_test + noise"]}, {"cell_type": "markdown", "metadata": {}, "source": ["adding noise may exceed normalized pixel values>1.0 or <0.0<br>\n", "clip pixel values >1.0 to 1.0 and <0.0 to 0.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n", "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["network parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_shape = (image_size, image_size, 1)\n", "batch_size = 32\n", "kernel_size = 3\n", "latent_dim = 16\n", "# encoder/decoder number of CNN layers and filters per layer\n", "layer_filters = [32, 64]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["build the autoencoder model<br>\n", "first build the encoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["inputs = Input(shape=input_shape, name='encoder_input')\n", "x = inputs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stack of Conv2D(32)-Conv2D(64)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filters in layer_filters:\n", "    x = Conv2D(filters=filters,\n", "               kernel_size=kernel_size,\n", "               strides=2,\n", "               activation='relu',\n", "               padding='same')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["shape info needed to build decoder model so we don't do hand computation<br>\n", "the input to the decoder's first Conv2DTranspose will have this shape<br>\n", "shape is (7, 7, 64) which can be processed by the decoder back to (28, 28, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shape = K.int_shape(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["generate the latent vector"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = Flatten()(x)\n", "latent = Dense(latent_dim, name='latent_vector')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["instantiate encoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encoder = Model(inputs, latent, name='encoder')\n", "encoder.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["build the decoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n", "# use the shape (7, 7, 64) that was earlier saved\n", "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n", "# from vector to suitable shape for transposed conv\n", "x = Reshape((shape[1], shape[2], shape[3]))(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stack of Conv2DTranspose(64)-Conv2DTranspose(32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filters in layer_filters[::-1]:\n", "    x = Conv2DTranspose(filters=filters,\n", "                        kernel_size=kernel_size,\n", "                        strides=2,\n", "                        activation='relu',\n", "                        padding='same')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reconstruct the denoised input"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outputs = Conv2DTranspose(filters=1,\n", "                          kernel_size=kernel_size,\n", "                          padding='same',\n", "                          activation='sigmoid',\n", "                          name='decoder_output')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["instantiate decoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["decoder = Model(latent_inputs, outputs, name='decoder')\n", "decoder.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["autoencoder = encoder + decoder<br>\n", "instantiate autoencoder model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n", "autoencoder.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Mean Square Error (MSE) loss function, Adam optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.compile(loss='mse', optimizer='adam')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["train the autoencoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autoencoder.fit(x_train_noisy,\n", "                x_train,\n", "                validation_data=(x_test_noisy, x_test),\n", "                epochs=10,\n", "                batch_size=batch_size)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["predict the autoencoder output from corrupted test images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_decoded = autoencoder.predict(x_test_noisy)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3 sets of images with 9 MNIST digits<br>\n", "1st rows - original images<br>\n", "2nd rows - images corrupted by noise<br>\n", "3rd rows - denoised images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rows, cols = 3, 9\n", "num = rows * cols\n", "imgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\n", "imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n", "imgs = np.vstack(np.split(imgs, rows, axis=1))\n", "imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n", "imgs = np.vstack([np.hstack(i) for i in imgs])\n", "imgs = (imgs * 255).astype(np.uint8)\n", "plt.figure()\n", "plt.axis('off')\n", "plt.title('Original images: top rows, '\n", "          'Corrupted Input: middle rows, '\n", "          'Denoised Input:  third rows')\n", "plt.imshow(imgs, interpolation='none', cmap='gray')\n", "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}